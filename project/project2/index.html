<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="author" content="Sanaa Mecci" />
    
    <link rel="shortcut icon" type="image/x-icon" href="../../img/favicon.ico">
    <title>Project 2: Modeling, Testing, and Predicting</title>
    <meta name="generator" content="Hugo 0.79.0" />
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="../../css/main.css" />
    <link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:200,400,200bold,400old" />
    
    <!--[if lt IE 9]>
			<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
			<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
		<![endif]-->

    
  </head>

  <body>
    <div id="wrap">
      
      <nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <a class="navbar-brand" href="../../"><i class="fa fa-home"></i></a>
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
    </div>
    <div class="navbar-collapse collapse" id="navbar">
      <ul class="nav navbar-nav navbar-right">
      
        
        <li><a href="../../post/">BLOG</a></li>
        
        <li><a href="../../projects/">PROJECTS</a></li>
        
        <li><a href="../../resume/">RESUME</a></li>
        
      
      </ul>
    </div>
  </div>
</nav>

      <div class="container">
        <div class="blog-post">
          <h3>
            <strong><a href="../../project/project2/">Project 2: Modeling, Testing, and Predicting</a></strong>
          </h3>
        </div>
 
<div class="blog-title">
          <h4>
         January 1, 0001 
            &nbsp;&nbsp;
            
          </h4>
        </div>

        <div class="panel panel-default">
          <div class="panel-body">
            <div class="blogpost">
              


<ul>
<li>**0. Introduction</li>
</ul>
<pre class="r"><code>library(dplyr)
library(tidyverse)
library(tidyr)
library(corrplot)
library(cluster)
drop &lt;- c(&quot;score&quot;, &quot;fcollege&quot;, &quot;mcollege&quot;, &quot;home&quot;, &quot;unemp&quot;,&quot;region&quot;)
CollegeDistance = read.csv(&quot;filename.csv&quot;)
CDistance=CollegeDistance[,!(names(CollegeDistance)%in%drop)]</code></pre>
<p>I have chosen a dataset which included cross-section data conducted by the Department of Education in 1980 regarding the distance of college and included high school students from 1,100 different high schools. The variables I will be analyzing are the distance (distance from a 4-year college), tuition (average state 4-year college tuition) and wage (the state hourly wage in manufacturing in 1980). Specifically, my aim was to analyze how those variables would relate to response variables such as ethnicity (African American, Hispanic, or other) and gender (m/f). Lastly, my two binary variables are income(which is scaled by high/low) and urban, if the school is in an urban area(which is scaled by yes/no). There are 4739 observations in total across 9 variables in the condensed dataset.</p>
<ul>
<li>**1. MANOVA</li>
</ul>
<pre class="r"><code>man1&lt;-manova(cbind(tuition,distance)~ethnicity, data=CDistance) 
summary(man1)</code></pre>
<pre><code>## Df Pillai approx F num Df den Df Pr(&gt;F)
## ethnicity 2 0.10169 126.85 4 9472 &lt; 2.2e-16 ***
## Residuals 4736
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>summary.aov(man1)</code></pre>
<pre><code>## Response tuition :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## ethnicity 2 50.62 25.3106 241.92 &lt; 2.2e-16 ***
## Residuals 4736 495.49 0.1046
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## Response distance :
## Df Sum Sq Mean Sq F value Pr(&gt;F)
## ethnicity 2 285.2 142.616 27.327 1.584e-12 ***
## Residuals 4736 24716.2 5.219
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>pairwise.t.test(CDistance$tuition,CDistance$ethnicity,p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  CDistance$tuition and CDistance$ethnicity 
## 
##          afam   hispanic
## hispanic &lt;2e-16 -       
## other    0.61   &lt;2e-16  
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(CDistance$distance,CDistance$ethnicity,p.adj=&quot;none&quot;)</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  CDistance$distance and CDistance$ethnicity 
## 
##          afam    hispanic
## hispanic 1.5e-12 -       
## other    6.2e-10 0.0095  
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>0.05/4 #bonferroni</code></pre>
<pre><code>## [1] 0.0125</code></pre>
<pre class="r"><code>1-.95^4 #type I error</code></pre>
<pre><code>## [1] 0.1854938</code></pre>
<pre class="r"><code>library(rstatix)
group &lt;- CDistance$ethnicity
DVs &lt;- CDistance %&gt;% dplyr::select(tuition, distance)
sapply(split(DVs,group), mshapiro_test)</code></pre>
<pre><code>##           afam        hispanic     other       
## statistic 0.7044855   0.6716225    0.7559214   
## p.value   5.78903e-35 1.671393e-38 2.546817e-55</code></pre>
<p>In total, there was 1 MANOVA test, 1 ANOVA test, and 2 pairwise t-tests, 4 in total, which leaves the probability that there would be, if left unadjusted, one type I error, 0.185. Using the Bonferroni correction, the significance level was adjusted to 0.0125. When analyzing ethnicity, we can see that the variables tuition and cost significantly differ. To test the MANOVA assumptions, the multivariate normality was tested for both groups but yielded a p value across both variables that was less than .05 so we can deduce that the multivariate normality assumption was violated so we did not have to test for the homogeneity. We can reject the null hypothesis that all of the MANOVA assumptions were met.</p>
<ul>
<li>**2. Randomization test</li>
</ul>
<pre class="r"><code>CDistance%&gt;%dplyr::group_by(urban)%&gt;%
dplyr:: summarize(means=mean(distance))%&gt;%dplyr::summarize(&quot;mean_diff:&quot;=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   `mean_diff:`
##          &lt;dbl&gt;
## 1        -1.57</code></pre>
<pre class="r"><code> rand_dist&lt;-vector()
for(i in 1:5000){ rando&lt;-data.frame(distance=sample(CDistance$distance),urban=CDistance$urban)
rand_dist[i]&lt;-mean(rando[rando$urban==&quot;yes&quot;,]$distance)- mean(rando[rando$urban==&quot;no&quot;,]$distance)}
 mean(rand_dist&gt;-1.5712)*2</code></pre>
<pre><code>## [1] 2</code></pre>
<pre class="r"><code>{hist(rand_dist,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = c(-1.5712, 1.5712),col=&quot;red&quot;)}</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>t.test(data=CDistance, distance~urban)</code></pre>
<pre><code>##
## Welch Two Sample t-test
##
## data: distance by urban
## t = 34.944, df = 4587.8, p-value &lt; 2.2e-16
## alternative hypothesis: true difference in means is not
equal to 0
## 95 percent confidence interval:
## 1.483114 1.659422
## sample estimates:
## mean in group no mean in group yes
## 2.1689133 0.5976449</code></pre>
<p>The null hypothesis is that the mean distance is the same for high school students who’s school is in an urban area versus high school students who’s school is not an urban area. The alternate hypothesis is that the mean distance is different for students who’s high school is in an urban area versus a non-urban area. Once performing the randomization test, a small p-value of &lt;2.2e-16 was yielded, allowing us to reject the null hypothesis. Thus, as we can see in the plot, there is a difference in the mean distance for students whose school is located in an urban area versus not in an urban area.</p>
<ul>
<li>**3. Linear Regression model</li>
</ul>
<pre class="r"><code>library(sandwich)
library(lmtest)
library(ggplot2)
CDistance$tuition_c &lt;- CDistance$tuition - mean(CDistance$tuition)
CDistance$distance_c &lt;- CDistance$distance - mean(CDistance$distance)
CDistance$wage_c &lt;- CDistance$wage - mean(CDistance$wage)
umfit&lt;-lm(tuition_c~urban*distance_c, data=CDistance)
coeftest(umfit)</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.0090683 0.0056559 1.6033 0.108925
## urbanyes -0.0773987 0.0237446 -3.2596 0.001123 **
## distance_c -0.0165037 0.0022479 -7.3419 2.466e-13 ***
## urbanyes:distance_c -0.0319212 0.0173263 -1.8424
0.065486 .
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>ggplot(CDistance, aes(tuition_c, distance_c)) + geom_point() + geom_smooth(method=&quot;lm&quot;)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>plot(CDistance$tuition_c, CDistance$distance_c)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-4-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>bptest(umfit)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  umfit
## BP = 61.768, df = 3, p-value = 2.463e-13</code></pre>
<pre class="r"><code>resids&lt;-umfit$resid
fitteds&lt;-umfit$fitted.values
ks.test(resids, &quot;pnorm&quot;, mean=0, sd(resids))</code></pre>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  resids
## D = 0.096733, p-value &lt; 2.2e-16
## alternative hypothesis: two-sided</code></pre>
<pre class="r"><code>coeftest(umfit, vcov = vcovHC(umfit))</code></pre>
<pre><code>##
## t test of coefficients:
##
## Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) 0.0090683 0.0056717 1.5989 0.1099179
## urbanyes -0.0773987 0.0225962 -3.4253 0.0006194 ***
## distance_c -0.0165037 0.0018186 -9.0750 &lt; 2.2e-16 ***
## urbanyes:distance_c -0.0319212 0.0168774 -1.8914
0.0586381 .
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>summary(umfit)$r.sq</code></pre>
<pre><code>## [1] 0.01315201</code></pre>
<p>All of the numeric variables involved in the interaction are mean-centered. Analyzing the intercept coefficient, we can see that for the students whose schools are located in an urban area, tend to be located to colleges that are further away from them. When looking at the assumptions of normality (fail to reject null) homoskedasticity (p-value less than 0.05), and linearity (graph is not linear, points are scattered everywhere), we can see from the diagrams that the assumptions were only met for normality and not for the other two tested. The regression results with robust standard errors showed a change in both standard errors and t values but no change in the coefficient estimates. The proportion of variance explained by the linear regression model is 0.01315.</p>
<ul>
<li>**4. Rerun same Regression model</li>
</ul>
<pre class="r"><code>set.seed(326)
boot_dat&lt;- sample_frac(CDistance, replace=T)
samp_distn&lt;-replicate(5000, {
boot_dat &lt;- sample_frac(CDistance, replace=T)
fiit &lt;- lm(tuition_c~urban*distance_c, data=boot_dat) 
coef(fiit) 
})
samp_distn %&gt;% t %&gt;% as.data.frame %&gt;%summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)   urbanyes  distance_c urbanyes:distance_c
## 1 0.005618219 0.02266476 0.001817113          0.01699397</code></pre>
<p>Once again, all of the numeric variables involved in the interaction are mean-centered. For the intercept SE and distance SEs, the bootstrapped values decreased slightly from the robust and original SEs. For the urban SE, the value slightly increased.</p>
<ul>
<li><strong>5. (25 pts)</strong> Logistic Regression model</li>
</ul>
<pre class="r"><code>library(ggplot2)
library(MASS)

cdd&lt;-CDistance%&gt;%dplyr::mutate(income=ifelse(income==&quot;low&quot;,0,1)) 
#CDistance=CDistance %&gt;% dplyr::mutate(income = ifelse(income == &quot;low&quot;,0,1))

cdd$distance_c= cdd$distance-mean(cdd$distance)
cdd$wage_c= cdd$wage-mean(cdd$wage)

fitt&lt;-glm(as.factor(income) ~ distance_c + wage_c, data=cdd,family=&quot;binomial&quot;) 
summary(fitt)</code></pre>
<pre><code>##
## Call:
## glm(formula = as.factor(income) ~ distance_c + wage_c,
family = &quot;binomial&quot;,
## data = cdd)
##
## Deviance Residuals:
## Min 1Q Median 3Q Max
## -1.0172 -0.8626 -0.7766 1.4609 2.3528
##
## Coefficients:
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -0.91993 0.03253 -28.280 &lt; 2e-16 ***
## distance_c -0.09084 0.01658 -5.481 4.24e-08 ***
## wage_c 0.11920 0.02409 4.947 7.52e-07 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1
##
## (Dispersion parameter for binomial family taken to be 1)
##
## Null deviance: 5690.4 on 4738 degrees of freedom
## Residual deviance: 5632.0 on 4736 degrees of freedom
## AIC: 5638
##
## Number of Fisher Scoring iterations: 4</code></pre>
<pre class="r"><code>coeftest(fitt)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) -0.919926 0.032529 -28.2801 &lt; 2.2e-16 ***
## distance_c -0.090843 0.016576 -5.4805 4.241e-08 ***
## wage_c 0.119201 0.024093 4.9474 7.520e-07 ***
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>prob&lt;-predict(fitt,type=&quot;response&quot;)
predict&lt;-ifelse(prob&gt;.5,1,0)
table(prediction=predict,truth=CDistance$income)%&gt;%addmargins</code></pre>
<pre><code>##           truth
## prediction high  low  Sum
##        0   1365 3374 4739
##        Sum 1365 3374 4739</code></pre>
<pre class="r"><code>(3374/4739) #acc</code></pre>
<pre><code>## [1] 0.7119645</code></pre>
<pre class="r"><code>(1365/1365) #tpr/sens</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>(3374/3374) #tnr/spec</code></pre>
<pre><code>## [1] 1</code></pre>
<pre class="r"><code>(1365/4739) #ppv</code></pre>
<pre><code>## [1] 0.2880355</code></pre>
<pre class="r"><code>library(plotROC)
library(ggplot2)
plotROC &lt;- ggplot(CDistance) + geom_roc(aes(d=income, m=prob), n.cuts=0) + geom_segment(aes(x=0, xend=1, y=0, yend=1),lty=2)
plotROC</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(plotROC)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.4335654</code></pre>
<pre class="r"><code>cdd$logit&lt;-predict(fitt)
cdd$income&lt;-factor(CDistance$income,levels=c(&quot;high&quot;,&quot;low&quot;))
head(cdd)</code></pre>
<pre><code>## X gender ethnicity urban wage distance tuition education
income tuition_c distance_c wage_c
## 1 1 male other yes 8.09 0.2 0.88915 12 high 0.07454177
-1.60287 -1.410506
## 2 2 female other yes 8.09 0.2 0.88915 12 low 0.07454177
-1.60287 -1.410506
## 3 3 male other yes 8.09 0.2 0.88915 12 low 0.07454177
-1.60287 -1.410506
## 4 4 male afam yes 8.09 0.2 0.88915 12 low 0.07454177
-1.60287 -1.410506
## 5 5 female other yes 8.09 0.4 0.88915 13 low 0.07454177
-1.40287 -1.410506
## 6 6 male other yes 8.09 0.4 0.88915 12 low 0.07454177
-1.40287 -1.410506
## logit
## 1 -0.9424494
## 2 -0.9424494
## 3 -0.9424494
## 4 -0.9424494
## 5 -0.9606180
## 6 -0.9606180</code></pre>
<pre class="r"><code>ggplot(cdd,aes(logit,fill=income))+geom_density(alpha=.3)+geom_vline(xintercept=0,lty=2)</code></pre>
<p><img src="../../project/project2_files/figure-html/unnamed-chunk-6-2.png" width="768" style="display: block; margin: auto;" /></p>
<p>When the students family’s income is high and corresponds to the variables distance and wage, the intercept coefficient shows us that the binary variable income is predicted to be -0.9199. When we hold the variable wage constant, with every 1 unit increase in the variable distance, results in a -.09084 decrease in distance. On the other hand, there’s a 0.1192 increase in the binary variable income with every 1 unit increase in distance, keeping wage constant. The accuracy of the logistic model is 0.711 (proportion of low income over total). The sensitivity(tpr/proportion of students whose family income is high reported correctly) and specification(tnr/ proportion of students whose family income is high reported incorrectly) values are both 1 which stands for the true positive and true negative rate respectively. The ppv was calculated to be 0.288. The AUC was calculated to be 0.433, which is bad. The low AUC value tells us that it is hard to predict if a student’s familial income would be high or low based off of how far a college is located from them, and the state hourly wage in manufacturing.</p>
<ul>
<li><strong>6. (25 pts)</strong> Logistic regression of all variables</li>
</ul>
<pre class="r"><code>library(tidyverse); library(lmtest)

class_diag&lt;-function(probs,truth){
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  f1=2*(sens*ppv)/(sens+ppv)

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE){
    truth&lt;-as.numeric(truth)-1}
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,f1,auc)
}

yep &lt;- cdd %&gt;% dplyr::select(-gender, -ethnicity, -urban, -wage, -distance, -tuition, -education)

fitl&lt;-glm(income~.,data=yep,family=&quot;binomial&quot;)
coeftest(fitl)</code></pre>
<pre><code>##
## z test of coefficients:
##
## Estimate Std. Error z value Pr(&gt;|z|)
## (Intercept) 1.0091e+00 4.0887e-02 24.6808 &lt; 2.2e-16 ***
## X -2.1797e-05 5.8937e-06 -3.6983 0.0002170 ***
## tuition_c -3.6471e-01 1.1559e-01 -3.1551 0.0016044 **
## distance_c 8.4550e-02 1.6604e-02 5.0922 3.54e-07 ***
## wage_c -8.7573e-02 2.5960e-02 -3.3734 0.0007424 ***
## logit NA NA NA NA
## ---
## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1
&#39; &#39; 1</code></pre>
<pre class="r"><code>probab &lt;- predict(fitl, data=&quot;response&quot;)
class_diag(probab,yep$income)</code></pre>
<pre><code>## acc sens spec ppv f1 auc
## low 0.7012028 0.9596918 0.06227106 0.7166888 0.8205778
0.5792071</code></pre>
<pre class="r"><code>set.seed(1234)#10fold
k=10
date&lt;-yep[sample(nrow(yep)),]
folds&lt;-cut(seq(1:nrow(yep)),breaks=k,labels=F) 
diags&lt;-NULL
for(i in 1:k){
college&lt;-date[folds!=i,] 
test&lt;-date[folds==i,]
truth&lt;-test$income

fitl&lt;-glm(income~distance_c+tuition_c,data=yep,family=&quot;binomial&quot;)
probs&lt;-predict(fitl,newdata = test,type=&quot;response&quot;)
diags&lt;-rbind(diags,class_diag(probs,truth)) 
}

diags%&gt;%summarize_all(mean)</code></pre>
<pre><code>##         acc sens spec       ppv        f1       auc
## 1 0.7119642    1    0 0.7119642 0.8316813 0.5574837</code></pre>
<pre class="r"><code>library(glmnet) #lasso
matrix &lt;- as.matrix(yep$income)
cddlast &lt;- model.matrix(income ~ ., data=yep)[,-1]
head(cddlast)</code></pre>
<pre><code>##   X  tuition_c distance_c    wage_c      logit
## 1 1 0.07454177   -1.60287 -1.410506 -0.9424494
## 2 2 0.07454177   -1.60287 -1.410506 -0.9424494
## 3 3 0.07454177   -1.60287 -1.410506 -0.9424494
## 4 4 0.07454177   -1.60287 -1.410506 -0.9424494
## 5 5 0.07454177   -1.40287 -1.410506 -0.9606180
## 6 6 0.07454177   -1.40287 -1.410506 -0.9606180</code></pre>
<pre class="r"><code>cv&lt;- cv.glmnet(cddlast, matrix, family=&quot;binomial&quot;)
lasso_fit &lt;- glmnet(cddlast, matrix, family=&quot;binomial&quot;, lambda = cv$lambda.1se)
coef(lasso_fit)</code></pre>
<pre><code>## 6 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                    s0
## (Intercept) 0.9049446
## X           0.0000000
## tuition_c   .        
## distance_c  .        
## wage_c      .        
## logit       .</code></pre>
<pre class="r"><code>set.seed(1234) #cvlasso
k=10
data&lt;-yep[sample(nrow(yep)),]
folds&lt;-cut(seq(1:nrow(yep)),breaks=k,labels=F) 
diags&lt;-NULL

for(i in 1:k){
train&lt;-data[folds!=i,]
test&lt;-data[folds==i,]
truth&lt;-test$income
fit&lt;-glm(income~tuition_c+wage_c+distance_c, data=yep, family = &quot;binomial&quot;)
probs&lt;-predict(fit,newdata = test,type=&quot;response&quot;)
diags&lt;-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags, mean)</code></pre>
<pre><code>##         acc sens spec       ppv        f1       auc
## 1 0.7119642    1    0 0.7119642 0.8316813 0.5696846</code></pre>
<p>The in-sample values calculated for accuracy, TPR(sensitivity), TNR(specificity), PPV(precision) and AUC are respectively: 0.7012, 0.9596, 0.0622, 0.7166, and 0.8205. The AUC is a very good value. For the 10-fold CV, the out-sample values calculated for accuracy, TPR, TNR, PPV, and AUC are respectively: 0.7119, 1, 0, 0.7119, 0.8316, 0.5574. The AUC in this case was bad and decreased compared to the in-sample classification. After running the LASSO regression having input all the variables as predictors, the variables to be retained were the most crucial predictors of income and should’ve had values next to them. None of the variables had any value next to them which tells us that no variable was a good predictor in familial income. A 10-fold CV was then performed on all of the variables regardless and yielded accuracy, TPR, TNR, PPV, and AUC values of: 0.7119, 1, 0, 0.7119, 0.8316, and 0.5696. The accuracy remained the same from the previous logistic test with only a slight increase in AUC, which was still a very poor value.</p>

            
        <hr>         <div class="related-posts">
                <h5>Related Posts</h5>
                
              </div> 
            </div>
          </div>

   <hr>  <div class="disqus">
  <div id="disqus_thread"></div>
  <script type="text/javascript">

    (function() {
      
      
      if (window.location.hostname == "localhost")
        return;

      var disqus_shortname = '';
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  <a href="http://disqus.com/" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</div> 
        </div>
      </div>
    </div>

    
    <footer>
  <div id="footer">
    <div class="container">
      <p class="text-muted">&copy; All rights reserved. Powered by <a href="https://gohugo.io/">Hugo</a> and
      <a href="http://www.github.com/nurlansu/hugo-sustain/">sustain</a> with ♥</p>
    </div>
  </div>
</footer>
<div class="footer"></div>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>

<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>
<script src="../../js/docs.min.js"></script>
<script src="../../js/main.js"></script>

<script src="../../js/ie10-viewport-bug-workaround.js"></script>


    
  </body>
</html>
